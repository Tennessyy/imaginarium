{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f8k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f30k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/coco.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/models/vse.zip\n",
    "!git clone https://github.com/ryankiros/visual-semantic-embedding.git\n",
    "!git clone https://github.com/fchollet/deep-learning-models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from random import sample\n",
    "from visual_semantic_embedding import tools, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Читаем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998,)\n",
      "(4473,)\n"
     ]
    }
   ],
   "source": [
    "words_text = {}\n",
    "words_list = ['1000', '4000']\n",
    "for num_word in words_list:\n",
    "    tmp = pd.read_csv('data/words/raw/top{0}_words.txt'.format(num_word), header = -1)\n",
    "    if tmp.shape[0]<tmp.shape[1]:\n",
    "        tmp = tmp.T\n",
    "    tmp = [str(x).replace(' ', '') for x in tmp[0]]\n",
    "    print np.array(tmp).shape\n",
    "    words_text[num_word] = {'array': np.array(tmp),\n",
    "                            'ind2word': {ind:word for ind, word in enumerate(tmp)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Читаем модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained_models/coco.npz\n",
      "Loading dictionary...\n",
      "Creating inverted dictionary...\n",
      "Loading model options...\n",
      "Loading model parameters...\n",
      "Compiling sentence encoder...\n",
      "Compiling image encoder...\n",
      "Packing up...\n",
      "pretrained_models/f8k.npz\n",
      "Loading dictionary...\n",
      "Creating inverted dictionary...\n",
      "Loading model options...\n",
      "Loading model parameters...\n",
      "Compiling sentence encoder...\n",
      "Compiling image encoder...\n",
      "Packing up...\n",
      "pretrained_models/f30k.npz\n",
      "Loading dictionary...\n",
      "Creating inverted dictionary...\n",
      "Loading model options...\n",
      "Loading model parameters...\n",
      "Compiling sentence encoder...\n",
      "Compiling image encoder...\n",
      "Packing up...\n"
     ]
    }
   ],
   "source": [
    "model_list = ['coco', 'f8k', 'f30k']\n",
    "model_weights = {}\n",
    "for model_name in model_list:\n",
    "    model_weights[model_name] = tools.load_model('pretrained_models/{0}.npz'.format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Делаем словарь с векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(998, 1024)\n",
      "(998, 1024)\n",
      "(998, 1024)\n",
      "(4473, 1024)\n",
      "(4473, 1024)\n",
      "(4473, 1024)\n"
     ]
    }
   ],
   "source": [
    "pretrained_vectors = {}\n",
    "for num_word in words_list:\n",
    "    for model_name in model_list:\n",
    "        name_pretrain = '{0}_{1}'.format(num_word, model_name)\n",
    "        pretrained_vectors[name_pretrain] = \\\n",
    "        tools.encode_sentences(model_weights[model_name],\n",
    "                                       words_text[num_word]['array'])\n",
    "        print pretrained_vectors[name_pretrain].shape\n",
    "        pd.DataFrame(pretrained_vectors[name_pretrain]).to_csv(\n",
    "            'data/words/coco/{0}.csv'.format(name_pretrain))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Берем тексты, делаем для них признаки\n",
    "###### https://gitlab.com/dikonov/Universal-Dictionary-of-Concepts/blob/master/data/csv/dict-nl-eng.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_text['df'] = {}\n",
    "table_semantic = pd.read_csv('data/words/raw/dict-nl-eng.csv', sep = '\\t', header = -1)[8:]\n",
    "table_semantic['word'] = table_semantic[0].apply(lambda x: x[1:-1] if ('-' not in x)\n",
    "                                                 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_wordnet(x, ind):\n",
    "    try:\n",
    "        return x.split('(')[1].split(')')[0].split(',')[0].split('>')[ind]\n",
    "    except:\n",
    "        return ''\n",
    "    \n",
    "table_semantic['definition'] = table_semantic[2].apply(lambda x: get_tag_wordnet(x, 1))\n",
    "table_semantic['concept'] = table_semantic[2].apply(lambda x: get_tag_wordnet(x, 2))\n",
    "table_semantic['smth'] = table_semantic[2].apply(lambda x: get_tag_wordnet(x, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Получаем для них вектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_semantic['concept'] = table_semantic[['definition', 'concept']].apply(\n",
    "    lambda x:  x[0] if x[1] == '' else x[1], axis = 1)\n",
    "table_semantic['definition'] = table_semantic[['definition', 'concept']].apply(\n",
    "    lambda x:  '' if x[1] == x[0] else x[0], axis = 1)\n",
    "\n",
    "table_semantic['pos'] = table_semantic[5].apply(lambda x: x[1:-1])\n",
    "table_semantic['title'] = table_semantic['word'].apply(lambda x: x.istitle())\n",
    "\n",
    "cols_list  = ['word', 'pos', 'concept', 'definition', 'smth', 'title']\n",
    "table_semantic = table_semantic[cols_list]\n",
    "#table_semantic[(table_semantic['title']) & (table_semantic['smth']!='iof')]['concept']\n",
    "#table_semantic[(table_semantic['title']) & (table_semantic['smth']=='iof')]['concept']\n",
    "#table_semantic['word'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мержим со словами из 1к и 4 к"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_1000 = pd.DataFrame(words_text['1000']['array'], columns = ['words_1000'])\n",
    "words_1000['ind'] = words_1000.index\n",
    "words_4000 = pd.DataFrame(words_text['4000']['array'], columns = ['words_4000'])\n",
    "words_4000['ind'] = words_4000.index\n",
    "\n",
    "table_semantic_1000 = table_semantic.merge(words_1000, left_on = 'word', right_on = 'words_1000')\n",
    "table_semantic_4000 = table_semantic.merge(words_4000, left_on = 'word', right_on = 'words_4000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_semantic_1000.to_csv('data/words/words1000_semantics.csv')\n",
    "table_semantic_4000.to_csv('data/words/words4000_semantics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Читаем картинки, строим эмбеддинги и извлекаем из них VGG19 фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шапка для картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "# чуть покрасивше картинки:\n",
    "#pd.set_option('display.mpl_style', 'default')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['axes.grid'] = True\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Ubuntu'\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', weight='bold')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10)\n",
    "# чтобы был русский шрифт\n",
    "from matplotlib import rc\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "rc('font', **font)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "py2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
