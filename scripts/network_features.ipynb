{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f8k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f30k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/coco.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/models/vse.zip\n",
    "!git clone https://github.com/ryankiros/visual-semantic-embedding.git\n",
    "!git clone https://github.com/fchollet/deep-learning-models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('/home/lichi/jupiter/imaginarium')\n",
    "from random import sample\n",
    "\n",
    "from PIL import Image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv1D,Activation, Reshape, Conv2D,Input, Dense, dot, multiply, add, concatenate, Lambda\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from visual import tools, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем сетку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем 5 случайных картинок, из них выбираем одну\n",
    "\n",
    "1) y - ohe номера картинки. \n",
    "\n",
    "2) X1 -  расстояние от картинки до топ 5 слов( часть речи, длина этих слов, сколько раз эти слова встречаются в топ-5 других картинок)\n",
    "\n",
    "3) X2 - расстояние от полученного среднего вектора слов до 5 картинок, сколько раз картинки встречаются в топ-5 этих слов\n",
    "\n",
    "4) Лосс - логлосс при обучении 2 игрока, при обучении 1 игрока - 1.5*p*(1-p)*(1-p) + p*p*(1-p)*1.5\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Читаем данные, обработанные до этого"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('preprocessed_data/words_coco_vectors.pickle', 'rb') as f:\n",
    "    words_vectors = pickle.load( f)\n",
    "with open('preprocessed_data/image_coco_vectors.pickle', 'rb') as f:\n",
    "    image_vectors = pickle.load( f)\n",
    "    \n",
    "    \n",
    "# Дампим массив, в котором содержатся индексы  топ10,\n",
    "# близких по mse слов-ассоциаций к картинке для каждой картинки\n",
    "with open('preprocessed_data/idx_words_array.pickle', 'rb') as f:\n",
    "    idx_words_array = pickle.load( f)\n",
    "# Дампим массив, в котором содержатся индексы  топ10,\n",
    "# близких по mse слов-ассоциаций к картинке для каждого ckjdf\n",
    "with open('preprocessed_data/idx_images_array.pickle', 'rb') as f:\n",
    "    idx_images_array = pickle.load( f)\n",
    "# Дампим массив, в котором содержатся инфа о том,\n",
    "# в скольки процентах случаев это слово входит в топ-10 ближайших для всех картинок\n",
    "with open('preprocessed_data/norm_idx_words_array.pickle', 'rb') as f:\n",
    "    norm_idx_words_array = pickle.load( f)\n",
    "# Дампим массив, в котором содержатся инфа о том,\n",
    "# в скольки процентах случаев эта картинка входит в топ-10 ближайших для всех слов\n",
    "with open('preprocessed_data/norm_idx_images_array.pickle', 'rb') as f:\n",
    "    norm_idx_images_array = pickle.load( f)\n",
    "# Дампим массив, в котором содержатся расстояние до топ k слов \n",
    "with open('preprocessed_data/mse_words_top_array.pickle', 'rb') as f:\n",
    "    mse_words_top_array = pickle.load( f)\n",
    "# Дампим массив, в котором содержатся расстояние до топ k слов \n",
    "with open('preprocessed_data/mse_words_top_array.pickle', 'rb') as f:\n",
    "    mse_words_top_array = pickle.load( f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая выборка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ind, y_ind, y, X1 = [], [], [], []\n",
    "X_img_freq = []\n",
    "num_samples = 100000\n",
    "num_images = idx_words_array.shape[0]\n",
    "num_words = idx_words_array.shape[1]\n",
    "k = 10\n",
    "for i in range(num_samples):\n",
    "    X_ind.append(np.array(sample(range(1,num_images), k)))\n",
    "    y_ind.append(sample(X_ind[i], 1))\n",
    "    y.append(np.array([1 if x==y_ind[i] else 0 for x in X_ind[i]]))\n",
    "    dist_words = mse_words_top_array[y_ind[i]]\n",
    "    freq_word = norm_idx_words_array[np.where(idx_words_array[0]==1)]\n",
    "    X1.append(np.concatenate([dist_words.reshape(k,1), freq_word.reshape(k,1)], axis = 1))\n",
    "    freq_image = norm_idx_images_array[np.where(idx_images_array[0]==1)]\n",
    "    X_img_freq.append(freq_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = image_vectors[X_ind].reshape(num_samples,1024,k)\n",
    "X1 = np.array(X1).reshape(num_samples,2,k)\n",
    "y = np.array(y).reshape(num_samples,1,k)\n",
    "X3 = X2.reshape(num_samples,k,1024)\n",
    "X30 = X3[:,0,:].reshape(num_samples,1024)\n",
    "X31 = X3[:,1,:].reshape(num_samples,1024)\n",
    "X_img_freq = np.array(X_img_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сетка, которая пока просто подбирает идеальное слово под случайно выбранную картинку для 1 агента,  а потом 2 агент просто выбирает ближайшее слово (или учит как выбирать dense слоем (тоже такой штраф за небанальность))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error_keras(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=2)\n",
    "k = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Сетка, которая пока просто подбирает идеальное слово под случайно выбранную картинку для 1 агента, \n",
    "# а потом 2 агент просто выбирает ближайшее слово\n",
    "\n",
    "# Входы 10 ближайших пар, заранее сгенерированные расстояния между ближайшими словами и картинками, и частоту топ 10 \n",
    "# близости каждого слова к ближайшим 10 картинкам\n",
    "inputs1 = Input(shape=(2,k))\n",
    "# Эмбеддинги для слов\n",
    "inputs2 = Input(shape=(1024,k))\n",
    "inputs21 = Input(shape=(k,1024))\n",
    "# OHE-вектор, какое слово было истинным\n",
    "inputs3 = Input(shape=(1,k))\n",
    "#  Учим свертку, которая делает штраф-поощрения за банальность (дистанция между словами, попсовость слов)\n",
    "# На выходе получили веса для каждого слова\n",
    "conv1d = Conv1D(k, (2), activation='softmax', padding = 'valid')(inputs1)\n",
    "#predictions = Dense(5, activation='softmax')(conv1d)\n",
    "# усредняем слова с весами, выученными сверткой\n",
    "merge_layer = multiply([conv1d, inputs2])\n",
    "# делаем повтор, чтобы потом считать новые минимальные дистанции\n",
    "sum_layer = Lambda(lambda x: K.repeat(K.sum(x, axis = 2), k), output_shape=(1024, k))(merge_layer)\n",
    "\n",
    "# считаем разницу между полученными средними одного и другого\n",
    "distance_layer = Lambda(lambda x: mean_squared_error_keras(x[0], x[1]),\n",
    "                        output_shape=(1,k))([inputs21, sum_layer])\n",
    "\n",
    "#features_img = concatenate([distance_layer, inputs3], axis = 1)\n",
    "#output = Conv1D(5, (2), activation='softmax', padding = 'valid')(features_img)\n",
    "\n",
    "dense_overfit = Dense(100, activation='relu')(distance_layer)\n",
    "# Выбираем правильный ответ (аналог агента)\n",
    "output = Dense(k, activation='softmax')(dense_overfit)\n",
    "\n",
    "#подбираем картинки\n",
    "model_keras = Model(inputs=[inputs1, inputs2, inputs21], outputs=output)\n",
    "model_keras.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 59s 586us/step - loss: 115.1315 - acc: 0.1002\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 54s 544us/step - loss: 115.1304 - acc: 0.1002\n",
      "Epoch 3/10\n",
      " 42500/100000 [===========>..................] - ETA: 30s - loss: 115.1317 - acc: 0.0994"
     ]
    }
   ],
   "source": [
    "model_keras.fit([X1, X2, X2.reshape(num_samples, k,1024)],y, epochs = 10, \n",
    "                verbose = True, batch_size = 500, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Отрисовать сетку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model_hard, to_file='model_hard.png')\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_keras).create(prog='dot', format='svg' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
