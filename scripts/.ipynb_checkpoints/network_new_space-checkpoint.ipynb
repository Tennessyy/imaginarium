{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f8k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f30k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/coco.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/models/vse.zip\n",
    "!git clone https://github.com/ryankiros/visual-semantic-embedding.git\n",
    "!git clone https://github.com/fchollet/deep-learning-models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "os.chdir('/home/lichi/jupiter/imaginarium')\n",
    "\n",
    "from random import sample\n",
    "from PIL import Image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv1D,Activation, Reshape, Conv2D,Input, Dense, dot, multiply, add, concatenate, Lambda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from visual import tools, evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('preprocessed_data/words_coco_vectors.pickle', 'rb') as f:\n",
    "    words_vectors = pickle.load( f)\n",
    "with open('preprocessed_data/image_coco_vectors.pickle', 'rb') as f:\n",
    "    image_vectors = pickle.load( f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Сэмплируем случайные k векторов\n",
    "def generate_arrays_from_file(image_vectors,words_vectors, num_samples = 50, k = 10, num_words = 998):\n",
    "    while 1:\n",
    "        X_images = []\n",
    "        y_true_image = []\n",
    "        for i in range(num_samples):\n",
    "            img = np.array(sample(range(1,len(image_vectors)), k))\n",
    "            X_images.append(img)\n",
    "            true_image = sample(img, 1)\n",
    "            y_true_image.append(np.array([1 if x==true_image else 0 for x in X_images[i]]))\n",
    "        # Эмбеддинги для всех картинок\n",
    "        X_images = image_vectors[X_images].reshape(num_samples,1024,k)\n",
    "        # Эмбеддинги для правильной картинки, размноженные 10 раз\n",
    "        t =np.array(X_images)[:,:,np.argmax(y_true_image)]\n",
    "        X_true_img = np.repeat(t.reshape(t.shape[0],t.shape[1],1),\n",
    "                               num_words,axis =2).reshape(num_samples, num_words, 1024)\n",
    "        # Эмбеддинги для всех текстов\n",
    "        X_all_texts = np.repeat(words_vectors.reshape(1, num_words, 1024),num_samples, axis = 0 )\n",
    "        # Решейплю\n",
    "        X_images = X_images.reshape(num_samples, k,1024)\n",
    "        # Ответы\n",
    "        y_true_image = np.array(y_true_image).reshape(num_samples,1, k)\n",
    "        yield ([X_images, X_true_img, X_all_texts], y_true_image)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучающая выборка 2 (Сделать генератор)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Датасет - подготавливаем наборы из 10 картинок , выбираем из них случайно одну\n",
    "num_samples = 2000\n",
    "k = 10\n",
    "num_words = 998\n",
    "X_images = []\n",
    "y_true_image = []\n",
    "for i in range(num_samples):\n",
    "    img = np.array(sample(range(1,len(image_vectors)), k))\n",
    "    X_images.append(img)\n",
    "    true_image = sample(img, 1)\n",
    "    y_true_image.append(np.array([1 if x==true_image else 0 for x in X_images[i]]))\n",
    "# Эмбеддинги для всех картинок\n",
    "X_images = image_vectors[X_images].reshape(num_samples,1024,k)\n",
    "# Эмбеддинги для правильной картинки, размноженные 10 раз\n",
    "t =np.array(X_images)[:,:,np.argmax(y_true_image)]\n",
    "X_true_img = np.repeat(t.reshape(t.shape[0],t.shape[1],1),num_words,axis =2).reshape(num_samples, num_words, 1024)\n",
    "# Эмбеддинги для всех текстов\n",
    "X_all_texts = np.repeat(words_vectors.reshape(1, num_words, 1024),num_samples, axis = 0 )\n",
    "# Решейплю\n",
    "X_images = X_images.reshape(num_samples, k,1024)\n",
    "# Ответы\n",
    "y_true_image = np.array(y_true_image).reshape(num_samples,1, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Генератор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_squared_error_keras(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=2)\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "def mean_squared_error_keras(y_true, y_pred):\n",
    "    return K.mean(K.cos(y_pred - y_true), axis=2)\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сетка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "k = 10\n",
    "num_words = 998\n",
    "# Вектора для k картинок\n",
    "X_images_net = Input(shape=(k,1024), name = 'X_images_net')\n",
    "\n",
    "# Вектор для правильной картинки, размноженной 1000 раз - по количеству слов\n",
    "X_image_true_net = Input(shape=(num_words, 1024), name = 'X_image_true_net')\n",
    "\n",
    "# Вектора для всех слов\n",
    "X_text_all_net = Input(shape = (num_words, 1024), name = 'X_text_all_net')\n",
    "\n",
    "# Вектор для того, какая картинка была авторской\n",
    "y_true_image_net = Input(shape=(1,k), name = 'y_true_image_net')\n",
    "\n",
    "conv_img_words2 = Dense(100, activation = 'softmax', name = 'dense_img_words2')\n",
    "\n",
    "# Эмбеддинги для правильной картинки (размноженной по числу слов)\n",
    "image_net2 = conv_img_words2(X_image_true_net)\n",
    "# Эмбединги для слов\n",
    "word_net2 = conv_img_words2(X_text_all_net)\n",
    "\n",
    "# Обрабатываем Dense слоем k картинок\n",
    "image_all_net2 = conv_img_words2(X_images_net)\n",
    "\n",
    "# Считаю расстояния от картинки до текста, представляю картинку как взвешенную сумму слов\n",
    "distance_layer2 = Lambda(lambda x: mean_squared_error_keras(x[0], x[1]),\n",
    "                        output_shape=(1,num_words), name = 'distance_layer2')([image_net2, word_net2])\n",
    "#weights_for_words2 = Dense(num_words, activation='softmax', name = 'weights_for_words2')(word_net2)\n",
    "\n",
    "# Меняем форму слоев, чтобы их перемножить\n",
    "weights_for_words2_resh = Reshape((1,num_words), name = 'weights_for_words2_resh')(distance_layer2)\n",
    "word_net2_resh = Reshape((emb_dim,num_words), name = 'word_net2_resh')(word_net2)\n",
    "\n",
    "# Перемножаем\n",
    "merge_layer2 = multiply([weights_for_words2_resh, word_net2_resh], name = 'merge_layer2')\n",
    "\n",
    "# Усредняем, получаем вектор для финального слова\n",
    "sum_layer2 = Lambda(lambda x: K.sum(x, axis = 2), output_shape=(1,emb_dim), name = 'sum_layer2')(merge_layer2)\n",
    "\n",
    "# Размножаем вектор для финального слова\n",
    "final_word_vector_k = Lambda(lambda x: K.repeat(x, k), output_shape=(10, emb_dim),\n",
    "                             name = 'final_word_vector_k')(sum_layer2)\n",
    "\n",
    "# Считаем расстояния от полученного вектора слов до k картинок\n",
    "distance_layer_final = Lambda(lambda x: mean_squared_error_keras(x[0], x[1]),\n",
    "                        output_shape=(1,k),\n",
    "                              name = 'distance_layer_final')([image_all_net2, final_word_vector_k])\n",
    "# Подаем в Dense\n",
    "#output2 = Activation('softmax', name = 'output2')(distance_layer_final)\n",
    "\n",
    "overfit_layer = Dense(1000, activation = 'relu', name = 'overfit_layer')(distance_layer_final)\n",
    "\n",
    "output2 = Dense(k, activation = 'softmax', name = 'output2')(overfit_layer)\n",
    "\n",
    "#подбираем картинки\n",
    "model_hard = Model(inputs=[X_images_net, X_image_true_net, X_text_all_net], outputs=output2)\n",
    "model_hard.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#\n",
    "# Бейзлайн - количество угаданных слов или лосс по фиксированным image captioning эмбеддингам"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_hard.fit([X_images, X_true_img, X_all_texts],y_true_image, epochs = 10, \n",
    "                verbose = True, batch_size = 50, validation_split=0.1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 146s 1s/step - loss: 11.5131 - acc: 0.1084\n",
      "Epoch 2/2\n",
      "100/100 [==============================] - 138s 1s/step - loss: 11.5148 - acc: 0.1044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc2d031e6d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 200\n",
    "fun_train = generate_arrays_from_file(image_vectors,words_vectors, num_samples = 50, k = 10, num_words = 998)\n",
    "#fun_val = generate_arrays_from_file(X_val, np.array(y_val), batch_size)\n",
    "#steps = len(X_train)/batch_size\\\n",
    "steps = 100\n",
    "epochs = 2\n",
    "model_hard.fit_generator(fun_train,steps, epochs, verbose=1, shuffle = True) #validation_steps=fun_val,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строю графики промежуточных слоев сетки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models \n",
    "layer_name = 'distance_layer2'\n",
    "intermediate_layer_model = models.Model(inputs=model_hard.input,\n",
    "                                 outputs=model_hard.get_layer(layer_name).output)\n",
    "intermediate_layer_model1 = models.Model(inputs=model_hard.input,\n",
    "                                 outputs=model_hard.get_layer('dense_img_words2').get_output_at(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 100\n",
    "weights_words = intermediate_layer_model.predict([X_images[:n], X_true_img[:n], X_all_texts[:n]])\n",
    "image_net2 = intermediate_layer_model1.predict([X_images[:n], X_true_img[:n], X_all_texts[:n]])\n",
    "word_net2 = intermediate_layer_model1.predict([X_images[:n], X_true_img[:n], X_all_texts[:n]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фитим сетку на всех картинках из coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model_hard, to_file='model_hard.png')\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model_hard).create(prog='dot', format='svg' ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_coco_imgs = 'data_coco_flkr/coco_test_ims.npy'\n",
    "images_coco = np.load(path_coco_imgs)\n",
    "image_vectors_coco = tools.encode_images(model, images_coco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "batch_size = 200\n",
    "fun_train = generate_arrays_from_file(image_vectors_coco,words_vectors, num_samples = 50, k = 10, num_words = 998)\n",
    "steps = 100\n",
    "epochs = 2\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(log_dir='Graph', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "#tbCallback.set_model(tbCallBack)\n",
    "\n",
    "model_hard.fit_generator(fun_train,steps, epochs, verbose=1,\n",
    "                         shuffle = True, callbacks=[tbCallBack]) #validation_steps=fun_val,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import keras\n",
    "keras.backend.set_session(\n",
    "    tf_debug.TensorBoardDebugWrapperSession(tf.Session(), \"lichi.haze.yandex.net:6007\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "# чуть покрасивше картинки:\n",
    "#pd.set_option('display.mpl_style', 'default')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['figure.figsize'] = 8, 6\n",
    "plt.rcParams['axes.grid'] = True\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'Ubuntu'\n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', family='serif')\n",
    "plt.rc('font', weight='bold')\n",
    "plt.rc('xtick', labelsize=10) \n",
    "plt.rc('ytick', labelsize=10)\n",
    "# чтобы был русский шрифт\n",
    "from matplotlib import rc\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "rc('font', **font)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
