{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f8k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/f30k.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/datasets/coco.zip\n",
    "!wget http://www.cs.toronto.edu/~rkiros/models/vse.zip\n",
    "!git clone https://github.com/ryankiros/visual-semantic-embedding.git\n",
    "!git clone https://github.com/fchollet/deep-learning-models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from random import sample\n",
    "\n",
    "from PIL import Image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from visual import tools, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lichi/jupiter/imaginarium/pretrained_models/coco.npz\n",
      "Loading dictionary...\n",
      "Creating inverted dictionary...\n",
      "Loading model options...\n",
      "Loading model parameters...\n",
      "Compiling sentence encoder...\n",
      "Compiling image encoder...\n",
      "Packing up...\n",
      "/home/lichi/jupiter/imaginarium/pretrained_models/f30k.npz\n",
      "Loading dictionary...\n",
      "Creating inverted dictionary...\n",
      "Loading model options...\n",
      "Loading model parameters...\n",
      "Compiling sentence encoder...\n",
      "Compiling image encoder...\n",
      "Packing up...\n"
     ]
    }
   ],
   "source": [
    "path_to_model =  '/home/lichi/jupiter/imaginarium/pretrained_models/coco.npz'\n",
    "path_to_model_f30k =  '/home/lichi/jupiter/imaginarium/pretrained_models/f30k.npz'\n",
    "model = tools.load_model(path_to_model = path_to_model)\n",
    "model_f30k = tools.load_model(path_to_model = path_to_model_f30k)\n",
    "#evaluation.evalrank(model, data='f8k', split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Читаем картинки, строим эмбеддинги и извлекаем из них VGG19 фичи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"fc..., inputs=Tensor(\"in...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img 17.jpeg\n",
      "img 4.jpeg\n",
      "img 16.jpeg\n",
      "img 3.jpeg\n",
      "img 8.jpeg\n",
      "img 20.jpeg\n",
      "img 23.jpeg\n",
      "img 18.jpeg\n",
      "img 15.jpeg\n",
      "img 13.jpeg\n",
      "img 2.jpeg\n",
      "img 22.jpeg\n",
      ".ipynb_checkpoints\n",
      "img 14.jpeg\n",
      "img 11.jpeg\n",
      "img 9.jpeg\n",
      "img 7.jpeg\n",
      "img 21.jpeg\n",
      "img 10.jpeg\n",
      "img 6.jpeg\n",
      "img 19.jpeg\n",
      "img 12.jpeg\n",
      "img 5.jpeg\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=True)\n",
    "model_vgg19 = Model(input=base_model.input, output=base_model.get_layer('fc2').output)\n",
    "\n",
    "paths_images = os.listdir('images')\n",
    "img_list = []\n",
    "feat_list = []\n",
    "for path in paths_images:\n",
    "    print path\n",
    "    if path!='.ipynb_checkpoints':\n",
    "        img=mpimg.imread('images/' + path,0)\n",
    "        img_crop = img[30:-30,30:-211]\n",
    "        h = img_crop.shape[0]\n",
    "        w = img_crop.shape[1]\n",
    "        img16 = []\n",
    "        feat16 = []\n",
    "        for i in np.arange(0,1,0.5):\n",
    "            for j in np.arange(0,1,0.25):\n",
    "                pic = img_crop[int(h*i):int(h*(i+1/2.)),int(w*j):int(w*(j+1/4.))]\n",
    "                pil = Image.fromarray(pic)\n",
    "                path_save = 'images_preprocessed/'+path[:-5]+str(i)+str(j)+ \".jpeg\"\n",
    "                pil.save(path_save)\n",
    "                img = image.load_img(path_save, target_size=(224, 224))\n",
    "                pic = image.img_to_array(img)\n",
    "                pic = np.expand_dims(pic, axis=0)\n",
    "                pic = preprocess_input(pic)\n",
    "                features = model_vgg19.predict(pic)\n",
    "                img16.append(img)\n",
    "                feat16.append(features)\n",
    "                \n",
    "        img_list += img16\n",
    "        feat_list += feat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_list = [x.reshape(4096) for x in feat_list]\n",
    "image_vectors = tools.encode_images(model, feat_list)\n",
    "image_vectors_f30k = tools.encode_images(model_f30k, feat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Берем топ-частотных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#words = pd.read_csv('words/4k_word_list.txt', sep = ',', header = -1)[0]\n",
    "words = pd.read_csv('words/top1000_words.txt', sep = ',', header = -1).T[0]\n",
    "words = np.array([x.replace(' ', '') for x in words])\n",
    "words_vectors = tools.encode_sentences(model, words, verbose=True)\n",
    "words_vectors_f30k = tools.encode_sentences(model_f30k, words, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохраняем представления для картинок в имаджинариуме и слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('preprocessed_data/words_coco_vectors.pickle', 'wb') as f:\n",
    "    pickle.dump(words_vectors, f)\n",
    "with open('preprocessed_data/image_coco_vectors.pickle', 'wb') as f:\n",
    "    pickle.dump(image_vectors, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
