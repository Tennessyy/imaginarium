{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "os.chdir('/home/lichi/jupiter/imaginarium')\n",
    "\n",
    "from random import sample\n",
    "from PIL import Image\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv1D,Activation, Reshape, Conv2D,Input, Dense, dot, multiply, add, concatenate, Lambda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from visual import tools, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Делаем сетку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_dim = 100\n",
    "k = 10\n",
    "num_words = 998\n",
    "# Вектора для k картинок\n",
    "X_images_net = Input(shape=(k,1024), name = 'X_images_net')\n",
    "\n",
    "# Вектор для правильной картинки, размноженной 1000 раз - по количеству слов\n",
    "X_image_true_net = Input(shape=(num_words, 1024), name = 'X_image_true_net')\n",
    "\n",
    "# Вектора для всех слов\n",
    "X_text_all_net = Input(shape = (num_words, 1024), name = 'X_text_all_net')\n",
    "\n",
    "# Вектор для того, какая картинка была авторской\n",
    "y_true_image_net = Input(shape=(1,k), name = 'y_true_image_net')\n",
    "\n",
    "conv_img_words2 = Dense(100, activation = 'softmax', name = 'dense_img_words2')\n",
    "\n",
    "# Эмбеддинги для правильной картинки (размноженной по числу слов)\n",
    "image_net2 = conv_img_words2(X_image_true_net)\n",
    "# Эмбединги для слов\n",
    "word_net2 = conv_img_words2(X_text_all_net)\n",
    "\n",
    "# Обрабатываем Dense слоем k картинок\n",
    "image_all_net2 = conv_img_words2(X_images_net)\n",
    "\n",
    "# Считаю расстояния от картинки до текста, представляю картинку как взвешенную сумму слов\n",
    "distance_layer2 = Lambda(lambda x: mean_squared_error_keras(x[0], x[1]),\n",
    "                        output_shape=(1,num_words), name = 'distance_layer2')([image_net2, word_net2])\n",
    "#weights_for_words2 = Dense(num_words, activation='softmax', name = 'weights_for_words2')(word_net2)\n",
    "\n",
    "# Меняем форму слоев, чтобы их перемножить\n",
    "weights_for_words2_resh = Reshape((1,num_words), name = 'weights_for_words2_resh')(distance_layer2)\n",
    "word_net2_resh = Reshape((emb_dim,num_words), name = 'word_net2_resh')(word_net2)\n",
    "\n",
    "# Перемножаем\n",
    "merge_layer2 = multiply([weights_for_words2_resh, word_net2_resh], name = 'merge_layer2')\n",
    "\n",
    "# Усредняем, получаем вектор для финального слова\n",
    "sum_layer2 = Lambda(lambda x: K.sum(x, axis = 2), output_shape=(1,emb_dim), name = 'sum_layer2')(merge_layer2)\n",
    "\n",
    "# Размножаем вектор для финального слова\n",
    "final_word_vector_k = Lambda(lambda x: K.repeat(x, k), output_shape=(10, emb_dim),\n",
    "                             name = 'final_word_vector_k')(sum_layer2)\n",
    "\n",
    "# Считаем расстояния от полученного вектора слов до k картинок\n",
    "distance_layer_final = Lambda(lambda x: mean_squared_error_keras(x[0], x[1]),\n",
    "                        output_shape=(1,k),\n",
    "                              name = 'distance_layer_final')([image_all_net2, final_word_vector_k])\n",
    "# Подаем в Dense\n",
    "#output2 = Activation('softmax', name = 'output2')(distance_layer_final)\n",
    "\n",
    "overfit_layer = Dense(1000, activation = 'relu', name = 'overfit_layer')(distance_layer_final)\n",
    "\n",
    "output2 = Dense(k, activation = 'softmax', name = 'output2')(overfit_layer)\n",
    "\n",
    "#подбираем картинки\n",
    "model_hard = Model(inputs=[X_images_net, X_image_true_net, X_text_all_net], outputs=output2)\n",
    "model_hard.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#\n",
    "# Бейзлайн - количество угаданных слов или лосс по фиксированным image captioning эмбеддингам"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
